{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":41880,"databundleVersionId":5677426,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns   \nfrom scipy.signal import butter, filtfilt\nfrom pathlib import Path  \nfrom scipy.stats import skew, kurtosis\n# import seglearn as sglearn        # For windowing and sequence modeling\nimport tsfresh     \nimport os\nfrom sklearn.preprocessing import StandardScaler\n\n \n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport polars as pl\nimport dask.dataframe as dd\nfrom pathlib import Path","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:20:46.842738Z","iopub.execute_input":"2025-10-15T18:20:46.843049Z","iopub.status.idle":"2025-10-15T18:20:58.068983Z","shell.execute_reply.started":"2025-10-15T18:20:46.843019Z","shell.execute_reply":"2025-10-15T18:20:58.067677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"# File paths for three training datasets\ndefog = Path('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/defog')\nnotype = Path('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/notype')\ntdcsfog = Path('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train/tdcsfog')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:20:58.071027Z","iopub.execute_input":"2025-10-15T18:20:58.071552Z","iopub.status.idle":"2025-10-15T18:20:58.077196Z","shell.execute_reply.started":"2025-10-15T18:20:58.071522Z","shell.execute_reply":"2025-10-15T18:20:58.075860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"defog_files = [f for f in os.listdir(defog) if f.endswith('.csv')]\n\n# List to store individual DataFrames\ndefog_list = []\n\nfor path in defog.glob(\"*.csv\"):\n    patient_id = path.stem  # removes .csv\n\n    df = pl.read_csv(path)\n    df = df.with_columns([\n        pl.lit(patient_id).alias(\"patient_id\")\n    ])\n    \n    defog_list.append(df)\n\ndefog_df = pl.concat(defog_list)\n# for f in defog_files:\n#     file_path = os.path.join(defog, f)\n#     df = pl.read_csv(file_path)\n#     df = df.with_columns([\n#         pl.lit(f).alias('file')  # Add filename as identifier\n#     ])\n#     defog_list.append(df)\n\n# # Concatenate into one large DataFrame\n# defog_df = pl.concat(defog_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:20:58.082338Z","iopub.execute_input":"2025-10-15T18:20:58.082711Z","iopub.status.idle":"2025-10-15T18:21:17.753791Z","shell.execute_reply.started":"2025-10-15T18:20:58.082684Z","shell.execute_reply":"2025-10-15T18:21:17.752708Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"defog_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:17.754759Z","iopub.execute_input":"2025-10-15T18:21:17.755089Z","iopub.status.idle":"2025-10-15T18:21:17.772773Z","shell.execute_reply.started":"2025-10-15T18:21:17.755059Z","shell.execute_reply":"2025-10-15T18:21:17.771786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tdcsfog_files = [f for f in os.listdir(tdcsfog) if f.endswith('.csv')]\n\n# List to store individual DataFrames\ntdcsfog_list = []\n\nfor path in tdcsfog.glob(\"*.csv\"):\n    patient_id = path.stem  # removes .csv\n\n    df = pl.read_csv(path)\n    df = df.with_columns([\n        pl.lit(patient_id).alias(\"patient_id\")\n    ])\n    \n    tdcsfog_list.append(df)\n\ntdcsfog_df = pl.concat(tdcsfog_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:17.773767Z","iopub.execute_input":"2025-10-15T18:21:17.774089Z","iopub.status.idle":"2025-10-15T18:21:38.697722Z","shell.execute_reply.started":"2025-10-15T18:21:17.774064Z","shell.execute_reply":"2025-10-15T18:21:38.696004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tdcsfog_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:38.702162Z","iopub.execute_input":"2025-10-15T18:21:38.702468Z","iopub.status.idle":"2025-10-15T18:21:38.711638Z","shell.execute_reply.started":"2025-10-15T18:21:38.702445Z","shell.execute_reply":"2025-10-15T18:21:38.709897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(defog_df.head())\n# print(defog_df.info())\nprint(defog_df.describe)\nprint(defog_df.shape)\nprint(defog_df.columns)   # list of column names\nprint(defog_df.dtypes)    # list of column types","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:38.712834Z","iopub.execute_input":"2025-10-15T18:21:38.713647Z","iopub.status.idle":"2025-10-15T18:21:38.736997Z","shell.execute_reply.started":"2025-10-15T18:21:38.713572Z","shell.execute_reply":"2025-10-15T18:21:38.735758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(tdcsfog_df.head())\n# print(tdcsfog_df.info())\nprint(tdcsfog_df.shape)     # (rows, columns)\nprint(tdcsfog_df.columns)   # list of column names\nprint(tdcsfog_df.dtypes) \nprint(tdcsfog_df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:38.737981Z","iopub.execute_input":"2025-10-15T18:21:38.738309Z","iopub.status.idle":"2025-10-15T18:21:40.028314Z","shell.execute_reply.started":"2025-10-15T18:21:38.738282Z","shell.execute_reply":"2025-10-15T18:21:40.026748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"events_df = pd.read_csv('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/events.csv')\nprint(events_df.head())\nprint(events_df.shape)   \nprint(events_df.columns)   \nprint(events_df.dtypes) \nprint(events_df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:40.029547Z","iopub.execute_input":"2025-10-15T18:21:40.029898Z","iopub.status.idle":"2025-10-15T18:21:40.093056Z","shell.execute_reply.started":"2025-10-15T18:21:40.029873Z","shell.execute_reply":"2025-10-15T18:21:40.091656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_defog_patients = defog_df[\"patient_id\"].unique()\n\nprint(unique_defog_patients)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:40.094490Z","iopub.execute_input":"2025-10-15T18:21:40.094901Z","iopub.status.idle":"2025-10-15T18:21:40.324218Z","shell.execute_reply.started":"2025-10-15T18:21:40.094871Z","shell.execute_reply":"2025-10-15T18:21:40.322796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Filter your Polars DF for a single patient and convert to pandas\ndf = defog_df.filter(pl.col(\"patient_id\") == 'be9d33541d').to_pandas()\n\n# 2. Plot\nplt.figure(figsize=(15, 6))\n\n# Plot acceleration\nplt.plot(df['Time'], df['AccV'], label='AccV', alpha=0.7)\nplt.plot(df['Time'], df['AccML'], label='AccML', alpha=0.7)\nplt.plot(df['Time'], df['AccAP'], label='AccAP', alpha=0.7)\n\n# 3. Plot events\nplt.plot(df['Time'], df['StartHesitation'], label='StartHesitation', alpha=0.7)\nplt.plot(df['Time'], df['Turn'], label='Turn', alpha=0.7)\nplt.plot(df['Time'], df['Walking'], label='Walking', alpha=0.7)\n\n\n# 4. Final touches\nplt.xlabel(\"Time\")\nplt.ylabel(\"Acceleration (g)\")\nplt.title(f\"Patient: {patient_id} - Acceleration + FOG Events\")\nplt.legend(loc=\"upper right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:40.326155Z","iopub.execute_input":"2025-10-15T18:21:40.326468Z","iopub.status.idle":"2025-10-15T18:21:41.454876Z","shell.execute_reply.started":"2025-10-15T18:21:40.326444Z","shell.execute_reply":"2025-10-15T18:21:41.453842Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"# Data types of features \nprint(f'DEFOG DATA TYPES:\\n{defog_df.dtypes}\\n')\nprint(f'TDCSFOG DATA TYPES:\\n{tdcsfog_df.dtypes}\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:41.455939Z","iopub.execute_input":"2025-10-15T18:21:41.456307Z","iopub.status.idle":"2025-10-15T18:21:41.464377Z","shell.execute_reply.started":"2025-10-15T18:21:41.456281Z","shell.execute_reply":"2025-10-15T18:21:41.462077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(tdcsfog_df.null_count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:41.465502Z","iopub.execute_input":"2025-10-15T18:21:41.465791Z","iopub.status.idle":"2025-10-15T18:21:41.495984Z","shell.execute_reply.started":"2025-10-15T18:21:41.465769Z","shell.execute_reply":"2025-10-15T18:21:41.494311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert accerlations in defog to m/s^2\nG_CONVERSION = 9.80665\ndefog_df[[\"AccV\", \"AccML\", \"AccAP\"]] *= G_CONVERSION\nprint(defog_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:41.497915Z","iopub.execute_input":"2025-10-15T18:21:41.498231Z","iopub.status.idle":"2025-10-15T18:21:42.133320Z","shell.execute_reply.started":"2025-10-15T18:21:41.498207Z","shell.execute_reply":"2025-10-15T18:21:42.132357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert the Valid and Task Columns to Integer Columns\ndef convert_valid_and_t(df):\n    df = df.with_columns(\n        pl.col(\"Valid\").cast(pl.Int8).alias(\"Valid\")\n    )\n    \n    df = df.with_columns(\n        pl.col(\"Task\").cast(pl.Int8).alias(\"Task\")\n    )\n    return df\ndefog_df = convert_valid_and_t(defog_df)\n# tdcsfog_df = convert_valid_and_t(tdcsfog_df)\n\n\nprint(defog_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:42.134546Z","iopub.execute_input":"2025-10-15T18:21:42.134867Z","iopub.status.idle":"2025-10-15T18:21:42.654228Z","shell.execute_reply.started":"2025-10-15T18:21:42.134845Z","shell.execute_reply":"2025-10-15T18:21:42.653336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a new column that contains the acceleration magnitude\ndef acc_magnitude(df):\n    df = df.with_columns(\n        (\n            (pl.col(\"AccV\") ** 2 + pl.col(\"AccML\") ** 2 + pl.col(\"AccAP\") ** 2).sqrt()\n        ).alias(\"Acc_MAGNITUDE\")\n    )\n\n    return df\n\ntdcsfog_df = acc_magnitude(tdcsfog_df)\ndefog_df = acc_magnitude(defog_df)\ndefog_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:42.655795Z","iopub.execute_input":"2025-10-15T18:21:42.656133Z","iopub.status.idle":"2025-10-15T18:21:44.249555Z","shell.execute_reply.started":"2025-10-15T18:21:42.656109Z","shell.execute_reply":"2025-10-15T18:21:44.248542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Standardize acceleration per patient for each training dataframe\ndef standardize_acc_by_patient(df: pl.DataFrame):\n    acc_cols = ['AccV', 'AccML', 'AccAP']\n    for col in acc_cols:\n        df = df.with_columns(\n            (\n                (pl.col(col) - pl.col(col).mean().over(\"patient_id\")) /\n                pl.col(col).std().over(\"patient_id\")\n            ).alias(col)  # overwrite original column\n        )\n    return df\n\ntdcsfog_df = standardize_acc_by_patient(tdcsfog_df)\ndefog_df = standardize_acc_by_patient(defog_df)\ndefog_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:44.250973Z","iopub.execute_input":"2025-10-15T18:21:44.251353Z","iopub.status.idle":"2025-10-15T18:21:49.589933Z","shell.execute_reply.started":"2025-10-15T18:21:44.251324Z","shell.execute_reply":"2025-10-15T18:21:49.589052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Band-pass Filter \ndef infer_fs(time_seconds: np.ndarray) -> float:\n    dt = np.diff(np.asarray(time_seconds, dtype=float))\n    dt = dt[np.isfinite(dt) & (dt > 0)]\n    if dt.size == 0:\n        raise ValueError(\"Cannot infer sampling frequency from Time column.\")\n    return 1.0 / np.median(dt)\n\ndef design_bandpass(low_hz: float, high_hz: float, fs: float, order: int = 4):\n    nyq = fs / 2.0\n    low = max(1e-6, low_hz / nyq)\n    high = min(0.999999, high_hz / nyq)\n    if not (0 < low < high < 1):\n        raise ValueError(f\"Invalid band for fs={fs:.3f}Hz: low={low_hz}Hz, high={high_hz}Hz\")\n    b, a = butter(order, [low, high], btype=\"band\")\n    return b, a\n\ndef bandpass_series(y: pd.Series, b, a) -> np.ndarray:\n    sig = pd.to_numeric(y, errors=\"coerce\").interpolate(limit_direction=\"both\").to_numpy(float)\n    return filtfilt(b, a, sig, method=\"pad\")\n\ndef bandpass_dataframe(df: pd.DataFrame, cols=('AccV','AccML','AccAP'),\n                       low_hz=0.1, high_hz=30.0, order=4) -> pd.DataFrame:\n    out = df.copy()\n    # Only keep columns that exist\n    cols = tuple([c for c in cols if c in out.columns])\n    if len(cols) == 0:\n        return out\n\n    fs = infer_fs(out['Time'].to_numpy())\n    b, a = design_bandpass(low_hz, high_hz, fs, order)\n    for col in cols:\n        out[f\"{col}_bp\"] = bandpass_series(out[col], b, a)\n    return out\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:49.591138Z","iopub.execute_input":"2025-10-15T18:21:49.591624Z","iopub.status.idle":"2025-10-15T18:21:49.605205Z","shell.execute_reply.started":"2025-10-15T18:21:49.591572Z","shell.execute_reply":"2025-10-15T18:21:49.603954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply Band-pass to all patients \ndef add_bandpass_to_all_patients(pl_df: pl.DataFrame,\n                                 cols=('AccV','AccML','AccAP'),\n                                 low_hz=0.1, high_hz=30.0, order=4) -> pl.DataFrame:\n    if \"patient_id\" not in pl_df.columns:\n        raise ValueError(\"Expected a 'patient_id' column.\")\n\n    out_chunks = []\n    # Unique patient list\n    patient_ids = pl_df.select(\"patient_id\").unique().to_series().to_list()\n\n    for pid in patient_ids:\n        g = pl_df.filter(pl.col(\"patient_id\") == pid).to_pandas()\n        # Skip tiny or malformed groups\n        if \"Time\" not in g.columns or len(g) < 5:\n            out_chunks.append(pl.from_pandas(g))  # just pass through\n            continue\n\n        try:\n            g_bp = bandpass_dataframe(g, cols=cols, low_hz=low_hz, high_hz=high_hz, order=order)\n        except Exception as e:\n            print(f\"[WARN] Skipping bandpass for patient {pid}: {e}\")\n            g_bp = g  # pass through raw if something fails\n\n        out_chunks.append(pl.from_pandas(g_bp))\n\n    return pl.concat(out_chunks, how=\"vertical_relaxed\")\n\ndefog_df_bp   = add_bandpass_to_all_patients(defog_df,   cols=('AccV','AccML','AccAP'),\n                                             low_hz=0.1, high_hz=30.0, order=4)\ntdcsfog_df_bp = add_bandpass_to_all_patients(tdcsfog_df, cols=('AccV','AccML','AccAP'),\n                                             low_hz=0.1, high_hz=30.0, order=4)\n\nprint(\"DEFOG with band-pass columns:\", [c for c in defog_df_bp.columns if c.endswith(\"_bp\")][:6], \"...\")\nprint(\"TDCSFOG with band-pass columns:\", [c for c in tdcsfog_df_bp.columns if c.endswith(\"_bp\")][:6], \"...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:21:49.606375Z","iopub.execute_input":"2025-10-15T18:21:49.606753Z","iopub.status.idle":"2025-10-15T18:26:03.317713Z","shell.execute_reply.started":"2025-10-15T18:21:49.606728Z","shell.execute_reply":"2025-10-15T18:26:03.316038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a new column that contains Time as seconds\ndef time_to_seconds(df, hertz):\n    df = df.with_columns(\n        (\n            (pl.col(\"Time\") / hertz)\n        ).alias(\"Time (seconds)\")\n    )\n\n    return df\n\ntdcsfog_df = time_to_seconds(tdcsfog_df, 128)\ndefog_df = time_to_seconds(tdcsfog_df, 100)\ndefog_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:03.319151Z","iopub.execute_input":"2025-10-15T18:26:03.319454Z","iopub.status.idle":"2025-10-15T18:26:03.866345Z","shell.execute_reply.started":"2025-10-15T18:26:03.319433Z","shell.execute_reply":"2025-10-15T18:26:03.865137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for outliers from acceleration\ndef detect_outliers(df: pl.DataFrame):\n    acc_cols = ['AccV', 'AccML', 'AccAP']\n    for col in acc_cols: \n        z_col = col\n        outlier_df = df.filter(pl.col(z_col).abs() > 3.0)\n    return outlier_df\nprint(detect_outliers(defog_df))\nprint(detect_outliers(tdcsfog_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:03.870525Z","iopub.execute_input":"2025-10-15T18:26:03.870872Z","iopub.status.idle":"2025-10-15T18:26:04.073472Z","shell.execute_reply.started":"2025-10-15T18:26:03.870849Z","shell.execute_reply":"2025-10-15T18:26:04.072274Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualize Acceleration  Signals During FoG Events","metadata":{}},{"cell_type":"code","source":"# Get unique patient IDs with a StartHesitation, Turn, and Walking event\n# Take a subset of 3 patients for each event\nStartHesPatients = (\n    defog_df.filter(pl.col(\"StartHesitation\") == 1)\n            .select(\"patient_id\")\n            .unique()\n            .to_series()[:3]  # take first 3\n)\nprint(f\"Patients with Start Hesitation: {StartHesPatients.to_list()}\")\n\nTurnPatients = (\n    defog_df.filter(pl.col(\"Turn\") == 1)\n            .select(\"patient_id\")\n            .unique()\n            .to_series()[:3]\n)\nprint(f\"Patients with Turn: {TurnPatients.to_list()}\")\n\nWalkingPatients = (\n    defog_df.filter(pl.col(\"Walking\") == 1)\n            .select(\"patient_id\")\n            .unique()\n            .to_series()[:3]\n)\nprint(f\"Patients with Walking: {WalkingPatients.to_list()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:04.074234Z","iopub.execute_input":"2025-10-15T18:26:04.074490Z","iopub.status.idle":"2025-10-15T18:26:04.236851Z","shell.execute_reply.started":"2025-10-15T18:26:04.074469Z","shell.execute_reply":"2025-10-15T18:26:04.235612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get unique patient IDs with a StartHesitation, Turn, and Walking event \n# (including band-pass)\nif {\"StartHesitation\",\"Turn\",\"Walking\"}.issubset(set(defog_df_bp.columns)):\n    StartHesPatients = (\n        defog_df_bp.filter(pl.col(\"StartHesitation\") == 1)\n                   .select(\"patient_id\").unique().to_series()[:3]\n    )\n    TurnPatients = (\n        defog_df_bp.filter(pl.col(\"Turn\") == 1)\n                   .select(\"patient_id\").unique().to_series()[:3]\n    )\n    WalkingPatients = (\n        defog_df_bp.filter(pl.col(\"Walking\") == 1)\n                   .select(\"patient_id\").unique().to_series()[:3]\n    )\n    print(f\"Patients with Start Hesitation: {StartHesPatients.to_list()}\")\n    print(f\"Patients with Turn: {TurnPatients.to_list()}\")\n    print(f\"Patients with Walking: {WalkingPatients.to_list()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:04.238017Z","iopub.execute_input":"2025-10-15T18:26:04.238702Z","iopub.status.idle":"2025-10-15T18:26:04.317788Z","shell.execute_reply.started":"2025-10-15T18:26:04.238642Z","shell.execute_reply":"2025-10-15T18:26:04.316612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start Hestitation\n# 1. Filter your Polars DF for a single patient and convert to pandas\ndf = defog_df.filter(pl.col(\"patient_id\") == '81262644e7').to_pandas()\n\n# 2. Plot\nplt.figure(figsize=(15, 6))\n\n# Plot acceleration\nplt.plot(df['Time'], df['AccV'], label='AccV', alpha=0.7)\nplt.plot(df['Time'], df['AccML'], label='AccML', alpha=0.7)\nplt.plot(df['Time'], df['AccAP'], label='AccAP', alpha=0.7)\n\n# 3. Plot events\nplt.plot(df['Time'], df['StartHesitation'], label='StartHesitation', alpha=0.7)\n\n\n# 4. Final touches\nplt.xlabel(\"Time\")\nplt.ylabel(\"Acceleration (g)\")\nplt.title(f\"Patient: {patient_id} - Acceleration + FOG Events\")\nplt.legend(loc=\"upper right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n# Start Hestitation\n# 1. Filter your Polars DF for a single patient and convert to pandas\ndf = defog_df.filter(pl.col(\"patient_id\") == '3ba3590a08').to_pandas()\n\n# 2. Plot\nplt.figure(figsize=(15, 6))\n\n# Plot acceleration\nplt.plot(df['Time'], df['AccV'], label='AccV', alpha=0.7)\nplt.plot(df['Time'], df['AccML'], label='AccML', alpha=0.7)\nplt.plot(df['Time'], df['AccAP'], label='AccAP', alpha=0.7)\n\n# 3. Plot events\nplt.plot(df['Time'], df['StartHesitation'], label='StartHesitation', alpha=0.7)\n\n\n# 4. Final touches\nplt.xlabel(\"Time\")\nplt.ylabel(\"Acceleration (g)\")\nplt.title(f\"Patient: {patient_id} - Acceleration + FOG Events\")\nplt.legend(loc=\"upper right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n# Start Hestitation\n# 1. Filter your Polars DF for a single patient and convert to pandas\ndf = defog_df.filter(pl.col(\"patient_id\") == 'd98358a75f').to_pandas()\n\n# 2. Plot\nplt.figure(figsize=(15, 6))\n\n# Plot acceleration\nplt.plot(df['Time'], df['AccV'], label='AccV', alpha=0.7)\nplt.plot(df['Time'], df['AccML'], label='AccML', alpha=0.7)\nplt.plot(df['Time'], df['AccAP'], label='AccAP', alpha=0.7)\n\n# 3. Plot events\nplt.plot(df['Time'], df['StartHesitation'], label='StartHesitation', alpha=0.7)\n\n\n# 4. Final touches\nplt.xlabel(\"Time\")\nplt.ylabel(\"Acceleration (g)\")\nplt.title(f\"Patient: {patient_id} - Acceleration + FOG Events\")\nplt.legend(loc=\"upper right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:04.319343Z","iopub.execute_input":"2025-10-15T18:26:04.319896Z","iopub.status.idle":"2025-10-15T18:26:05.820637Z","shell.execute_reply.started":"2025-10-15T18:26:04.319864Z","shell.execute_reply":"2025-10-15T18:26:05.819450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Patient in defog bp with Start Hesitation \npatient_id = \"e069a57511\" \ndfp = defog_df_bp.filter(pl.col(\"patient_id\") == patient_id).to_pandas()\n\nplt.figure(figsize=(16,7))\n\n# Raw\nplt.plot(dfp[\"Time\"], dfp.get(\"AccV\", pd.Series()),   label=\"AccV (raw)\",   alpha=0.35)\nplt.plot(dfp[\"Time\"], dfp.get(\"AccML\", pd.Series()),  label=\"AccML (raw)\",  alpha=0.35)\nplt.plot(dfp[\"Time\"], dfp.get(\"AccAP\", pd.Series()),  label=\"AccAP (raw)\",  alpha=0.35)\n\n# Filtered (if present)\nif \"AccV_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccV_bp\"],  label=\"AccV (0.1–30 Hz)\",  linewidth=1.5)\nif \"AccML_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccML_bp\"], label=\"AccML (0.1–30 Hz)\", linewidth=1.5)\nif \"AccAP_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccAP_bp\"], label=\"AccAP (0.1–30 Hz)\", linewidth=1.5)\n\n# Event overlays\nfor ev in [\"StartHesitation\", \"Turn\", \"Walking\"]:\n    if ev in dfp.columns:\n        plt.plot(dfp[\"Time\"], dfp[ev], label=ev, alpha=0.6)\n\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Acceleration (m/s²)  (or z-score if standardized)\")\nplt.title(f\"Patient {patient_id} – Raw vs Band-pass (Start Hesitation)\")\nplt.legend(ncol=3)\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Patient in defog bp that has turn \npatient_id = \"771d69d829\" \ndfp = defog_df_bp.filter(pl.col(\"patient_id\") == patient_id).to_pandas()\n\nplt.figure(figsize=(16,7))\n\n# Raw\nplt.plot(dfp[\"Time\"], dfp.get(\"AccV\", pd.Series()),   label=\"AccV (raw)\",   alpha=0.35)\nplt.plot(dfp[\"Time\"], dfp.get(\"AccML\", pd.Series()),  label=\"AccML (raw)\",  alpha=0.35)\nplt.plot(dfp[\"Time\"], dfp.get(\"AccAP\", pd.Series()),  label=\"AccAP (raw)\",  alpha=0.35)\n\n# Filtered (if present)\nif \"AccV_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccV_bp\"],  label=\"AccV (0.1–30 Hz)\",  linewidth=1.5)\nif \"AccML_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccML_bp\"], label=\"AccML (0.1–30 Hz)\", linewidth=1.5)\nif \"AccAP_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccAP_bp\"], label=\"AccAP (0.1–30 Hz)\", linewidth=1.5)\n\n# Event overlays \nfor ev in [\"StartHesitation\", \"Turn\", \"Walking\"]:\n    if ev in dfp.columns:\n        plt.plot(dfp[\"Time\"], dfp[ev], label=ev, alpha=0.6)\n\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Acceleration (m/s²)  (or z-score if standardized)\")\nplt.title(f\"Patient {patient_id} – Raw vs Band-pass (Turn)\")\nplt.legend(ncol=3)\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Patient in defog bp that has Walking \npatient_id = \"4c3aa8ea6e\" \ndfp = defog_df_bp.filter(pl.col(\"patient_id\") == patient_id).to_pandas()\n\nplt.figure(figsize=(16,7))\n\n# Raw\nplt.plot(dfp[\"Time\"], dfp.get(\"AccV\", pd.Series()),   label=\"AccV (raw)\",   alpha=0.35)\nplt.plot(dfp[\"Time\"], dfp.get(\"AccML\", pd.Series()),  label=\"AccML (raw)\",  alpha=0.35)\nplt.plot(dfp[\"Time\"], dfp.get(\"AccAP\", pd.Series()),  label=\"AccAP (raw)\",  alpha=0.35)\n\n# Filtered (if present)\nif \"AccV_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccV_bp\"],  label=\"AccV (0.1–30 Hz)\",  linewidth=1.5)\nif \"AccML_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccML_bp\"], label=\"AccML (0.1–30 Hz)\", linewidth=1.5)\nif \"AccAP_bp\" in dfp:\n    plt.plot(dfp[\"Time\"], dfp[\"AccAP_bp\"], label=\"AccAP (0.1–30 Hz)\", linewidth=1.5)\n\nfor ev in [\"StartHesitation\", \"Turn\", \"Walking\"]:\n    if ev in dfp.columns:\n        plt.plot(dfp[\"Time\"], dfp[ev], label=ev, alpha=0.6)\n\nplt.xlabel(\"Time (s)\")\nplt.ylabel(\"Acceleration (m/s²)  (or z-score if standardized)\")\nplt.title(f\"Patient {patient_id} – Raw vs Band-pass (Walking)\")\nplt.legend(ncol=3)\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:05.821910Z","iopub.execute_input":"2025-10-15T18:26:05.822267Z","iopub.status.idle":"2025-10-15T18:26:13.962100Z","shell.execute_reply.started":"2025-10-15T18:26:05.822237Z","shell.execute_reply":"2025-10-15T18:26:13.960664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_time_features_pd(\n    df: pd.DataFrame,\n    fs: float,\n    win_s: float,\n    hop_s: float,\n    signal_cols=('AccX','AccY','AccZ','GyroX','GyroY','GyroZ'),\n    label_cols=None,                 # e.g. ['StartHesitation','Turn','Walking','Event']\n    id_cols=None,                    # e.g. ['subject_id','series_id','id'] to carry through\n):\n    df = df.copy()\n    n = len(df)\n    win = int(round(fs*win_s))\n    hop = int(round(fs*hop_s))\n    if win <= 0 or hop <= 0:\n        raise ValueError(\"win_s and hop_s must be > 0\")\n\n    # Pre-pull arrays for speed\n    X = df.loc[:, signal_cols].to_numpy(dtype=float)\n\n    # Helper feature fns (safe on NaNs/empties)\n    def feats_one(w):\n        f = {}\n        # basic stats\n        f.update({f'{c}_mean': np.nanmean(w[:,i]) for i,c in enumerate(signal_cols)})\n        f.update({f'{c}_var' : np.nanvar (w[:,i]) for i,c in enumerate(signal_cols)})\n        f.update({f'{c}_std' : np.nanstd (w[:,i]) for i,c in enumerate(signal_cols)})\n        f.update({f'{c}_min' : np.nanmin (w[:,i]) for i,c in enumerate(signal_cols)})\n        f.update({f'{c}_max' : np.nanmax (w[:,i]) for i,c in enumerate(signal_cols)})\n        f.update({f'{c}_median': np.nanmedian(w[:,i]) for i,c in enumerate(signal_cols)})\n        f.update({f'{c}_iqr': np.nanpercentile(w[:,i],75)-np.nanpercentile(w[:,i],25) for i,c in enumerate(signal_cols)})\n\n        # energy & rms\n        f.update({f'{c}_energy': np.nansum(np.square(w[:,i]))/len(w) for i,c in enumerate(signal_cols)})\n        f.update({f'{c}_rms'   : np.sqrt(np.nanmean(np.square(w[:,i]))) for i,c in enumerate(signal_cols)})\n\n        # skew & kurt\n        for i,c in enumerate(signal_cols):\n            col = w[:,i]\n            f[f'{c}_skew'] = skew(col, nan_policy='omit', bias=False)\n            f[f'{c}_kurt'] = kurtosis(col, nan_policy='omit', fisher=True, bias=False)\n\n        # vector features for tri-axial groups\n        if set(['AccX','AccY','AccZ']).issubset(signal_cols):\n            ax = [signal_cols.index('AccX'), signal_cols.index('AccY'), signal_cols.index('AccZ')]\n            acc = w[:,ax]\n            mag = np.sqrt(np.sum(acc**2, axis=1))\n            f['Acc_mag_mean'] = np.nanmean(mag)\n            f['Acc_mag_std']  = np.nanstd(mag)\n            # Signal Magnitude Area (SMA)\n            f['Acc_sma'] = (np.nansum(np.abs(acc), axis=0).sum()) / len(mag)\n\n            # correlations\n            for (a,b) in [('AccX','AccY'),('AccX','AccZ'),('AccY','AccZ')]:\n                i1, i2 = signal_cols.index(a), signal_cols.index(b)\n                col1, col2 = w[:,i1], w[:,i2]\n                if np.all(np.isfinite(col1)) and np.all(np.isfinite(col2)) and len(col1) > 1:\n                    f[f'corr_{a}_{b}'] = np.corrcoef(col1, col2)[0,1]\n                else:\n                    f[f'corr_{a}_{b}'] = np.nan\n\n        if set(['GyroX','GyroY','GyroZ']).issubset(signal_cols):\n            gx = [signal_cols.index('GyroX'), signal_cols.index('GyroY'), signal_cols.index('GyroZ')]\n            gyro = w[:,gx]\n            mag = np.sqrt(np.sum(gyro**2, axis=1))\n            f['Gyro_mag_mean'] = np.nanmean(mag)\n            f['Gyro_mag_std']  = np.nanstd(mag)\n            f['Gyro_sma'] = (np.nansum(np.abs(gyro), axis=0).sum()) / len(mag)\n            for (a,b) in [('GyroX','GyroY'),('GyroX','GyroZ'),('GyroY','GyroZ')]:\n                i1, i2 = signal_cols.index(a), signal_cols.index(b)\n                col1, col2 = w[:,i1], w[:,i2]\n                if np.all(np.isfinite(col1)) and np.all(np.isfinite(col2)) and len(col1) > 1:\n                    f[f'corr_{a}_{b}'] = np.corrcoef(col1, col2)[0,1]\n                else:\n                    f[f'corr_{a}_{b}'] = np.nan\n\n        return f\n\n    rows = []\n    start_idx = 0\n    win_id = 0\n    while start_idx + win <= n:\n        end_idx = start_idx + win\n        w = X[start_idx:end_idx, :]\n        feat = feats_one(w)\n        # add time/window metadata\n        feat['win_id'] = win_id\n        feat['t_start_s'] = start_idx / fs\n        feat['t_end_s']   = (end_idx-1) / fs\n\n        # bring-through IDs from the *end* row of the window (common in DEFoG baselines)\n        if id_cols:\n            for c in id_cols:\n                feat[c] = df.iloc[end_idx-1][c]\n\n        # aggregate labels if provided (ANY>0 inside window)\n        if label_cols:\n            sub = df.iloc[start_idx:end_idx]\n            feat['label_any'] = bool((sub[label_cols].fillna(0).to_numpy() > 0).any())\n            for c in label_cols:\n                feat[f'label_{c}'] = bool((sub[c].fillna(0).to_numpy() > 0).any())\n\n        rows.append(feat)\n        win_id += 1\n        start_idx += hop\n\n    return pd.DataFrame(rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:13.963541Z","iopub.execute_input":"2025-10-15T18:26:13.963926Z","iopub.status.idle":"2025-10-15T18:26:13.991503Z","shell.execute_reply.started":"2025-10-15T18:26:13.963893Z","shell.execute_reply":"2025-10-15T18:26:13.989746Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Extracting Time Domain Features","metadata":{}},{"cell_type":"code","source":"DATA_DIR = Path(\"/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/train\")\n\nprint(\"Available training folders:\", [p.name for p in DATA_DIR.iterdir()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:13.993126Z","iopub.execute_input":"2025-10-15T18:26:13.993836Z","iopub.status.idle":"2025-10-15T18:26:14.036407Z","shell.execute_reply.started":"2025-10-15T18:26:13.993795Z","shell.execute_reply":"2025-10-15T18:26:14.035151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tdcsfog_file = list((DATA_DIR / \"tdcsfog\").glob(\"*.csv\"))[0]\ndefog_file   = list((DATA_DIR / \"defog\").glob(\"*.csv\"))[0]\nnotype_file  = list((DATA_DIR / \"notype\").glob(\"*.csv\"))[0]\n\nprint(\"Sample files chosen:\")\nprint(\"tdcsfog:\", tdcsfog_file.name)\nprint(\"defog:\", defog_file.name)\nprint(\"notype:\", notype_file.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:14.037835Z","iopub.execute_input":"2025-10-15T18:26:14.038165Z","iopub.status.idle":"2025-10-15T18:26:14.071584Z","shell.execute_reply.started":"2025-10-15T18:26:14.038140Z","shell.execute_reply":"2025-10-15T18:26:14.069849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tdcsfog_df = pd.read_csv(tdcsfog_file)\ndefog_df   = pd.read_csv(defog_file)\nnotype_df  = pd.read_csv(notype_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:14.074945Z","iopub.execute_input":"2025-10-15T18:26:14.075314Z","iopub.status.idle":"2025-10-15T18:26:14.659144Z","shell.execute_reply.started":"2025-10-15T18:26:14.075289Z","shell.execute_reply":"2025-10-15T18:26:14.658107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef tdcsfog_time_features(df, fs=128.0, win_s=2.0, hop_s=0.5):\n    \"\"\"\n    Extract time-domain features from accelerometer data in tdcsfog_df.\n    Works purely in pandas.\n    \"\"\"\n\n    # --- auto-detect accelerometer columns ---\n    cols = list(df.columns)\n    lower = {c.lower(): c for c in cols}\n    candidates = [\n        ['AccX','AccY','AccZ'],\n        ['AccelX','AccelY','AccelZ'],\n        ['acc_x','acc_y','acc_z'],\n        ['AccV','AccML','AccAP'],\n        ['accv','accml','accap'],\n    ]\n    acc_cols = None\n    for trio in candidates:\n        found = [lower.get(c.lower()) for c in trio]\n        if all(found):\n            acc_cols = found\n            break\n    if acc_cols is None:\n        acc_cols = [c for c in cols if re.search('acc', c, re.I)][:3]\n    if len(acc_cols) < 3:\n        raise KeyError(f\"Could not find 3 accelerometer columns. Found: {acc_cols}\")\n\n    # --- label columns ---\n    label_cols = [c for c in ['StartHesitation','Turn','Walking'] if c in df.columns]\n\n    # --- window setup ---\n    win = int(round(fs * win_s))\n    hop = int(round(fs * hop_s))\n    n = len(df)\n\n    X = df[acc_cols].to_numpy(dtype=float)\n    rows = []\n    start = 0\n    win_id = 0\n\n    while start + win <= n:\n        end = start + win\n        W = X[start:end, :]\n        f = {}\n\n        # per-axis features\n        for i, c in enumerate(acc_cols):\n            w = W[:, i]\n            f[f'{c}_mean']   = np.nanmean(w)\n            f[f'{c}_std']    = np.nanstd(w)\n            f[f'{c}_var']    = np.nanvar(w)\n            f[f'{c}_min']    = np.nanmin(w)\n            f[f'{c}_max']    = np.nanmax(w)\n            f[f'{c}_median'] = np.nanmedian(w)\n            q75, q25 = np.nanpercentile(w, [75, 25])\n            f[f'{c}_iqr']    = q75 - q25\n            f[f'{c}_energy'] = np.nansum(w**2) / len(w)\n            f[f'{c}_rms']    = np.sqrt(np.nanmean(w**2))\n            f[f'{c}_skew']   = skew(w, nan_policy='omit', bias=False)\n            f[f'{c}_kurt']   = kurtosis(w, nan_policy='omit', fisher=True, bias=False)\n\n        # vector magnitude features\n        mag = np.sqrt(np.sum(W**2, axis=1))\n        f['Acc_mag_mean'] = np.nanmean(mag)\n        f['Acc_mag_std']  = np.nanstd(mag)\n        f['Acc_sma']      = np.nansum(np.abs(W)) / len(W)\n\n        # correlations\n        def corr_safe(a,b):\n            if len(a) > 1 and np.isfinite(a).all() and np.isfinite(b).all():\n                return np.corrcoef(a,b)[0,1]\n            return np.nan\n        f[f'corr_{acc_cols[0]}_{acc_cols[1]}'] = corr_safe(W[:,0], W[:,1])\n        f[f'corr_{acc_cols[0]}_{acc_cols[2]}'] = corr_safe(W[:,0], W[:,2])\n        f[f'corr_{acc_cols[1]}_{acc_cols[2]}'] = corr_safe(W[:,1], W[:,2])\n\n        # labels (if exist)\n        if label_cols:\n            sub = df.iloc[start:end][label_cols].fillna(0).to_numpy()\n            f['label_any'] = bool((sub > 0).any())\n            for j, c in enumerate(label_cols):\n                f[f'label_{c}'] = bool((sub[:, j] > 0).any())\n\n        # window metadata\n        f['win_id'] = win_id\n        f['t_start_s'] = start / fs\n        f['t_end_s']   = (end - 1) / fs\n\n        rows.append(f)\n        win_id += 1\n        start += hop\n\n    return pd.DataFrame(rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:14.660494Z","iopub.execute_input":"2025-10-15T18:26:14.660850Z","iopub.status.idle":"2025-10-15T18:26:14.680762Z","shell.execute_reply.started":"2025-10-15T18:26:14.660821Z","shell.execute_reply":"2025-10-15T18:26:14.679479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# parameters\nFS = 128.0\nWIN = 2.0   # 2 seconds per window\nHOP = 0.5   # 0.5-second step\n\ntdcsfog_feats = tdcsfog_time_features(tdcsfog_df, fs=FS, win_s=WIN, hop_s=HOP)\n\nprint(\"Detected accelerometer columns:\", [c for c in tdcsfog_feats.columns if 'mean' in c][:3])\nprint(\"Shape:\", tdcsfog_feats.shape)\ntdcsfog_feats.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T18:26:14.682303Z","iopub.execute_input":"2025-10-15T18:26:14.682681Z","iopub.status.idle":"2025-10-15T18:26:15.778487Z","shell.execute_reply.started":"2025-10-15T18:26:14.682650Z","shell.execute_reply":"2025-10-15T18:26:15.777344Z"}},"outputs":[],"execution_count":null}]}